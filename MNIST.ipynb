{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.1.post2'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义一些超参数\n",
    "BATCH_SIZE = 512  #512\n",
    "EPOCHS = 2       #20,需要2G显存\n",
    "#查找硬件，如果有GPU则用GPU，没有则用CPU\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# 加载训练数据,DataLoader的参数，例子为dataset(从中加载数据的数据集)，batch_size(每次抽取的样本数),shuffle(True:每次抽取都是随机抽取)\n",
    "# transforms 来自torchvision，是pytorch中的图像预处理包\n",
    "# transforms.Compose()是将多个步骤合在一起执行\n",
    "# transfroms.ToTensor()将shape为(H, W, C)的nump.ndarray或img转为shape为(C, H, W)的tensor\n",
    "# 其将每一个数值归一化到[0,1]，其归一化方法比较简单，直接除以255即可\n",
    "# transforms.Normalize((),())第一个参数是std，第二个是mean，公式是(x-mean)/std,因为输入图片通道数为1，所以只有一个值\n",
    "# datasets.MNIST的参数说明\n",
    "#  root（string）– 数据集的根目录，其中存放processed/training.pt和processed/test.pt文件。\n",
    "#  train（bool, 可选）– 如果设置为True，从training.pt创建数据集，否则从test.pt创建。\n",
    "#  download（bool, 可选）– 如果设置为True, 从互联网下载数据并放到root文件夹下。如果root目录下已经存在数据，不会再次下载。\n",
    "#  transform（可被调用 , 可选）– 一种函数或变换，输入PIL图片，返回变换之后的数据。如：transforms.RandomCrop。\n",
    "#  target_transform （可被调用 , 可选）– 一种函数或变换，输入目标，进行变换。\n",
    "###\n",
    "train_data = datasets.MNIST('data',train=True,download=True,\n",
    "                  transform=transforms.Compose([\n",
    "                      transforms.ToTensor(),\n",
    "                      transforms.Normalize((0.1307,),(0.3081,))]))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载测试数据\n",
    "test_data = datasets.MNIST('data',train=False, \n",
    "                    transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,),(0.3081,))]))\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,shuffle=True)\n",
    "\n",
    "#print(enumerate(test_loader))\n",
    "test_x = torch.unsqueeze(test_data.data,dim=1).type(torch.FloatTensor)[:2000]/255.\n",
    "test_y = test_data.targets[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个网络结果\n",
    "# nn.Module是所有神经网络模块的基类，自己定义的模型要继承它\n",
    "# super是调用父类函数的一种方法，调用了父类函数的初始化函数\n",
    "# python3.x版本super().__init__()即可，python2.x则是super(Net,self).__init__()\n",
    "\n",
    "# class torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True)\n",
    "# in_channels(int) – 输入信号的通道\n",
    "# out_channels(int) – 卷积产生的通道\n",
    "# kerner_size(int or tuple) - 卷积核的尺寸\n",
    "# stride(int or tuple, optional) - 卷积步长\n",
    "# padding(int or tuple, optional) - 输入的每一条边补充0的层数\n",
    "# dilation(int or tuple, optional) – 卷积核元素之间的间距\n",
    "# groups(int, optional) – 从输入通道到输出通道的阻塞连接数\n",
    "# bias(bool, optional) - 如果bias=True，添加偏置\n",
    "\n",
    "# view函数\n",
    "# 第一个参数1将第一个维度的大小设定成1，后一个-1就是说第二个维度的大小=元素总数目/第一个维度的大小\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1,10,5)   # in: 1,28x28  out: 10,24x24\n",
    "        self.conv2 = nn.Conv2d(10,20,3)  # in: 10,12x12(池化之后) out: 20,10x10\n",
    "        self.fc1 = nn.Linear(20*10*10,500) #in: 20*10*10(所有像素点扁平化) out: 500\n",
    "        self.fc2 = nn.Linear(500,100)      #in: 500  out: 100\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # 在MNIST的数据集里面，size(0)为60000\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x)\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out,2,2)\n",
    "        out = self.conv2(out)\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # log_softmax是对softmax的结果取log\n",
    "        # softmax对n维输入张量运用Softmax函数，将张量的每个元素缩放到（0,1）区间且和为1\n",
    "        out = F.log_softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
      "Linear(in_features=2000, out_features=500, bias=True)\n"
     ]
    }
   ],
   "source": [
    "# 实例化一个网络，然后使用.to方法将网络移动到GPU/CPU\n",
    "model = Net().to(DEVICE)\n",
    "\n",
    "# 实例化一个优化器,参数是model的所有参数\n",
    "# model.parameters()\n",
    "# 返回模块参数的迭代器。 这通常被传递给优化器\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "print(model.conv1)\n",
    "print(model.fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练函数\n",
    "def train(model,device,train_loader,optimizer,epoch):\n",
    "    # model.train() 将模式设置为训练模型,仅仅当模型中有Dropout和BatchNorm是才会有影响\n",
    "    # 因为下面还有个model.eval()，这两种模式用的Dropout和BatchNorm都不同\n",
    "    model.train()\n",
    "    # enumerate enumerate()函数用于将一个可遍历的数据对象(如列表、元组或字符串)组合为一个索引序列，同时列出数据和数据下标\n",
    "    for batch_idx,(data,target) in enumerate(train_loader):\n",
    "        # 利用.to将数据传送到GPU/CPU计算\n",
    "        data,target = data.to(device),target.to(device)\n",
    "        # optimizer.zero_grad() \n",
    "        # 将所有模型的参数的梯度设置为0\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        # torch.nn.functional.nll_loss(input, target, weight=None, size_average=True)\n",
    "        # nll_loss和log_softmax组成了cross_entropy，可以用cross_entropy替代\n",
    "        # torch.nn.functional.cross_entropy(input, target, weight=None, size_average=True)\n",
    "        loss = F.nll_loss(output,target)\n",
    "        # loss反向传播\n",
    "        loss.backward()\n",
    "        # 优化器优化参数\n",
    "        optimizer.step()\n",
    "        #输出训练过程\n",
    "        if(batch_idx+1)%30 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader),loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义测试函数\n",
    "# “with torch.no_grad(): ”：为了防止跟踪历史（和使用内存）\n",
    "# 你还可以用“with torch.no_grad(): ”来包装代码块\n",
    "# 这在评估一个模型时特别有用，因为模型可能有可训练参数（具有属性“requiresgrad=True”）\n",
    "# 但我们并不需要整个模型的所有梯度\n",
    "\n",
    "# torch.max()简单来说是返回一个tensor中的最大值\n",
    "# troch.max()[1]， 只返回最大值的每个索引\n",
    "\n",
    "# torch.eq()比较两个数。(001)和(010)结果就是(100) 1：true 2：false\n",
    "\n",
    "def test(model, device, testloader):\n",
    "    # 开始测试模式\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, traget = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output,target, reduction='sum').item()\n",
    "            pred = output.max(1,keepdim=True)[1]\n",
    "            # traget.view_as(pred) target的形状改成和pred相同的\n",
    "            correct += pred.eq(traget.view_as(pred)).sum().item()\n",
    "        \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    #输出测试结果\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.342360\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.234517\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.190526\n",
      "\n",
      "Test set: Average loss: 0.1134, Accuracy: 9674/10000 (97%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.079068\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.074464\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.083048\n",
      "\n",
      "Test set: Average loss: 0.0648, Accuracy: 9799/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#执行函数进行网络训练\n",
    "for epoch in range(1,EPOCHS+1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存网络\n",
    "def save():\n",
    "    # 保存整个网络\n",
    "    torch.save(model,'model/MNIST_model.pkl') \n",
    "    # 保存网络的参数\n",
    "    # torch.save(model.state_dict(),'model/MNIST_model_Params.pkl') \n",
    "    \n",
    "save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载整个网络\n",
    "def restore_net():\n",
    "    MNIST_model = torch.load('model/MNIST_model.pkl')\n",
    "    return MNIST_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载网络参数\n",
    "def restore_params():\n",
    "    MNIST_modelParams = Net()\n",
    "    MNIST_modelParams.load_state_dict(torch.load('model、MNIST_modelParams'))\n",
    "    return MNIST_modelParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "60000\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 显示MNIST数据的图片\n",
    "def show_data():\n",
    "    #print(train_data.train_data[0])\n",
    "    print(train_data.data.size())\n",
    "    print(train_data.data.size(0))\n",
    "    print(train_data.targets.size())\n",
    "    #print(train_data.train_labels[0])\n",
    "    plt.imshow(train_data.data[0].numpy(),cmap='gray')\n",
    "    plt.title('%i' % train_data.targets[0])\n",
    "    plt.show()\n",
    "\n",
    "show_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 6 9 0 1 5 9 7 8 4 9 6 6 5 4 0 7 4 0 1] prediction number\n",
      "[0 6 9 0 1 5 9 7 3 4 9 6 6 5 4 0 7 4 0 1] real number\n"
     ]
    }
   ],
   "source": [
    "# 打印前10的结果\n",
    "test_output = model(test_x[10:30])\n",
    "pred_y = test_output.max(1,keepdim=True)[1].data.numpy().squeeze()\n",
    "print(pred_y,'prediction number')\n",
    "print(test_y[10:30].numpy(),'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
